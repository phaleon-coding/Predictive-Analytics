# -*- coding: utf-8 -*-
"""Proyek Pertama: Predictive Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yE47gQp2gPLtLms1Q_0vLAc-HLrNmlSj

# Data Understanding

## Data Loading
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Kaggle"
# %cd /content/gdrive/My Drive/Kaggle

!kaggle datasets download -d vjchoudhary7/hr-analytics-case-study

import zipfile
local_zip = "/content/gdrive/MyDrive/Kaggle/hr-analytics-case-study.zip"
zip_ref = zipfile.ZipFile(local_zip, "r")
zip_ref.extractall("/content/gdrive/MyDrive/Kaggle")
zip_ref.close()

!rm /content/gdrive/MyDrive/Kaggle/hr-analytics-case-study.zip
!rm /content/gdrive/MyDrive/Kaggle/data_dictionary.xlsx
!rm /content/gdrive/MyDrive/Kaggle/in_time.csv
!rm /content/gdrive/MyDrive/Kaggle/out_time.csv

import numpy as np
import pandas as pd

general_data = pd.read_csv("/content/gdrive/MyDrive/Kaggle/general_data.csv", sep=",")
employee_survey_data = pd.read_csv("/content/gdrive/MyDrive/Kaggle/employee_survey_data.csv", sep=",")
manager_survey_data = pd.read_csv("/content/gdrive/MyDrive/Kaggle/manager_survey_data.csv", sep=",")

"""## Exploratory Data Analysis - Deskripsi Variabel"""

general_data.head()

employee_survey_data.head()

manager_survey_data.head()

general_data.info()

employee_survey_data.info()

manager_survey_data.info()

general_data.describe()

employee_survey_data.describe()

manager_survey_data.describe()

print(general_data.BusinessTravel.unique())
print(general_data.Department.unique())
print(general_data.EducationField.unique())
print(general_data.Gender.unique())
print(general_data.MaritalStatus.unique())
print(general_data.StandardHours.unique())
print(general_data.Over18.unique())

"""## Exploratory Data Analysis - Menangani Missing Value"""

general_data.drop(columns=["EmployeeCount", "JobRole", "Over18", "StandardHours"], inplace=True)

general_data = general_data.merge(employee_survey_data, how="inner", on="EmployeeID", sort="EmployeeID")
general_data = general_data.merge(manager_survey_data, how="inner", on="EmployeeID", sort="EmployeeID")
general_data.drop(columns=["EmployeeID"], inplace=True)

general_data.dropna(axis=0, how="any", inplace=True)

"""## Exploratory Data Analysis - Univariate Analysis"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set()

numerical_features = ["Age", "DistanceFromHome", "MonthlyIncome", "NumCompaniesWorked", "PercentSalaryHike", "StockOptionLevel", "TotalWorkingYears", "TrainingTimesLastYear", "YearsAtCompany", "YearsSinceLastPromotion", "YearsWithCurrManager"]
categorical_features = ["Attrition", "BusinessTravel", "Department", "Education", "EducationField", "Gender", "JobLevel", "MaritalStatus", "EnvironmentSatisfaction", "JobSatisfaction", "WorkLifeBalance", "JobInvolvement", "PerformanceRating"]

f, axes = plt.subplots(4, 4, figsize=(20, 15))

j = 0
for i, feature in enumerate(categorical_features, 1):
  df = pd.DataFrame(general_data[feature].value_counts())
  df.reset_index(inplace=True)
  df = df.rename(columns = {feature: "count"})
  df = df.rename(columns = {'index': feature})
  df.plot(ax=axes[i-4*j-1, j], x = str(feature), y ="count", kind="bar")
  if i % 4 == 0:
    j += 1

plt.tight_layout()
plt.suptitle('Categorical Features Univariate Analysis')
plt.subplots_adjust(top=0.95)
plt.show()

general_data.hist(bins=50, figsize=(20,15))
plt.suptitle('Numerical Features Univariate Analysis')
plt.subplots_adjust(top=0.95)
plt.show()

"""## Exploratory Data Analysis - Multivariate Analysis"""

f, axes = plt.subplots(4, 4, figsize=(25, 15))

j = 0
for i, feature in enumerate(categorical_features, 1):
  sns.histplot(data=general_data, x=str(feature), stat="count", hue="Attrition", ax=axes[i-4*j-1, j])
  if i % 4 == 0:
    j += 1

plt.tight_layout()
plt.suptitle('Categorical Features Multivariate Analysis')
plt.subplots_adjust(top=0.95)
plt.show()

f, axes = plt.subplots(4, 3, figsize=(20, 15))

j = 0
for i, feature in enumerate(numerical_features, 1):
  sns.boxplot(data=general_data, x="Attrition", y=str(feature), ax=axes[i-4*j-1, j])
  if i % 4 == 0:
    j += 1

plt.tight_layout()
plt.suptitle('Numerical Features Multivariate Analysis')
plt.subplots_adjust(top=0.95)
plt.show()

"""# Data Preparation"""

from sklearn.preprocessing import LabelEncoder

labelEncoder_X = LabelEncoder()
general_data['BusinessTravel'] = labelEncoder_X.fit_transform(general_data['BusinessTravel'])
general_data['Department'] = labelEncoder_X.fit_transform(general_data['Department'])
general_data['EducationField'] = labelEncoder_X.fit_transform(general_data['EducationField'])
general_data['Gender'] = labelEncoder_X.fit_transform(general_data['Gender'])
general_data['MaritalStatus'] = labelEncoder_X.fit_transform(general_data['MaritalStatus'])

general_data['Attrition'] = labelEncoder_X.fit_transform(general_data['Attrition'])

general_data.head()

corr = general_data.iloc[: , :19].corr()
plt.figure(figsize=(16,10))
sns.heatmap(corr,annot=True)
plt.show()

from sklearn.decomposition import PCA

pca = PCA(n_components=1, random_state=1)
pca.fit(general_data[['YearsAtCompany','YearsSinceLastPromotion', "YearsWithCurrManager"]])
general_data['YearsInCompany'] = pca.transform(general_data.loc[:, ('YearsAtCompany','YearsSinceLastPromotion', "YearsWithCurrManager")]).flatten()
general_data.drop(['YearsAtCompany','YearsSinceLastPromotion', "YearsWithCurrManager"], axis=1, inplace=True)

pca = PCA(n_components=1, random_state=1)
pca.fit(general_data[['TotalWorkingYears', "Age"]])
general_data['YearsOfWorking'] = pca.transform(general_data.loc[:, ('TotalWorkingYears', "Age")]).flatten()
general_data.drop(['TotalWorkingYears', "Age"], axis=1, inplace=True)

from sklearn.model_selection import train_test_split

X = general_data.drop(["Attrition"], axis = 1)
y = general_data["Attrition"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)

from sklearn.preprocessing import StandardScaler

Scaler_X = StandardScaler()
X_train = Scaler_X.fit_transform(X_train)
X_test = Scaler_X.transform(X_test)

general_data.describe().round(4)

"""# Model Development

### Model Development: Logistic Regression
"""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(X_train,y_train)
y_pred_lr = lr.predict(X_test)

"""### Model Development: K-Nearest Neighbor"""

from sklearn.neighbors import KNeighborsClassifier
 
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)

"""### Model Development: Support Vector Classifier"""

from sklearn.svm import SVC

svc = SVC()
svc.fit(X_train, y_train)
y_pred_svc = svc.predict(X_test)

"""# Model Evaluation"""

from sklearn.metrics import balanced_accuracy_score

acc_score = pd.DataFrame(columns=['balanced_accuracy_score'], index=['KNN','LR', 'SVC'])
classifiers = {'KNN': KNeighborsClassifier(), 'LR': LogisticRegression(), 'SVC': SVC()}

for name, classifier in classifiers.items():
  acc_score.loc[name, 'balanced_accuracy_score'] = balanced_accuracy_score(y_true=y_test, y_pred=classifier.fit(X_train, y_train).predict(X_test))
 
pd.DataFrame(acc_score)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

f, axes = plt.subplots(1, 3, figsize=(20, 5), sharey='row')

for i, (key, classifier) in enumerate(classifiers.items()):
    y_pred = classifier.fit(X_train, y_train).predict(X_test)
    cf_matrix = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(cf_matrix, display_labels=classifier.classes_)
    disp.plot(ax=axes[i], xticks_rotation=45)
    disp.ax_.set_title(key)
    disp.im_.colorbar.remove()
    disp.ax_.set_xlabel('')
    if i!=0:
        disp.ax_.set_ylabel('')

f.text(0.4, 0.1, 'Predicted label', ha='left')
plt.subplots_adjust(wspace=0.40, hspace=0.1)

f.colorbar(disp.im_, ax=axes)
plt.show()

from sklearn.metrics import precision_recall_fscore_support

precision_recall_score = pd.DataFrame(columns=['precision', 'recall', 'fscore', 'support'], index=['KNN','LR', 'SVC'])

for name, classifier in classifiers.items():
  for i, column in enumerate(precision_recall_score.columns):
    precision_recall_score.loc[name, column] = precision_recall_fscore_support(y_true=y_test, y_pred=classifier.fit(X_train, y_train).predict(X_test), average="binary")[i]

pd.DataFrame(precision_recall_score)